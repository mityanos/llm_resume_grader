llm:
  model: "gpt-4o-mini-2024-07-18"

  # sampling / generation params (passed verbatim to OpenAI)
  params:
    temperature: 0.0
    top_p: 1.0
    frequency_penalty: 0
    presence_penalty: 0
    max_tokens: 1000

  retry_max: 6          # max attempts on 429 / 5xx

grading:
  scale: {A: 4, B: 3, C: 2, D: 1}

paths:
  system_prompt: "system_prompt.md"
  candidates_glob: "candidates/*.md"
  out_md: "results.md"
  out_json: "results.json"
